
Kafka Theory
------------

Apache kafka was originated by Linked in and later become an open source Apache product
Kafka is written in Java and scala
Kafka is fast, scalable, durable, fault tolerant and distributed by design
Apache kafka reduces the data pipelines
It makes system communication more simple and manageable
With kafka it is easy to establish remote communication and send messages across network

Kafka feature
-------------
1. Scalable -- Highly scalable system with no downtime. Kafka cluster having multiple broker
 will take care of all the messages coming from the producers.
2. Hige volume of data can be taken care by Kafka which are generated by producers and send 
them to consumer seamlessly.
3. Fault tolerant -- if there is failure of one node then all data which is present in that 
node will have replicas on some other system
4. Durable - it is durable because it is uses distributed commit log i;e messages persist on 
the disk as fast as possible  
5. Performance is good performance. high throughput- large amount of data transfered in a given time.

Components:
-----------
Brokers: they are servers that manage and mediate the conversation between two different system.
They are responsible for the delivery of the messages to the right party.

Messages - It is simply the bytes of array and any objects can be stored in any format like json, String etc.

Topic - Messages are published stored and oragnized in topics

Clusters - In Kafka more than 1 broker , a set of servers is collectively is known as clusters.
It is group of system having one instance of kafka broker.

Partitions: Every broker holds few partition and each partition can be either a leader or replicas for a topic.
All read and write of a topic go via the leader which is responsible for updating replicas with new data
If leader fails replica takes over.

Kafka Producers:
--------------------
Producers send messages to topic.
It select the topic to send the message per topic
It can implement priority system which are based on sending message to certain partition depending 
upon the priority of the record.
It sends the messages to the partition based on record's key
It don't wait for the acknowledment from the broker and will keep sending messages to the broker

Kafka Broker:
--------------------
A cluster typically consists of multiple brokers to maintain load balance
A broker on receiving messages from the producer assigns offset to them and and commits the messages to the disk storage.
One broker instance can handle thousands to read and write per second and Terabytes of messages
Backups of topic partition are present in multiple brokers
If a one of the brokers is down then replicas broker will be selected as leader for the partition

Kafka Topics and Partition:
----------------------------------
Messages in kafka are categorized into topic
Topics are broken down into number of partition
Reading of message can be from begining to end or skip or rewind to any point of the partition by providing offset value
offset values are sequentital number provided to messages
Partition can be hosted on different servers, thus a single topic can be scaled horizontally across multiple servers

Lets assume a topic is configured to 4 partitions and partition has an id 0,1,2,3 and if set the replication factor to 3, 
then kafka will create three identical replicas on each partition which means partition 0 will have 3 replicas , similarly 
partition 1,2,3 each will have 3 replicas .
id of the replica will be same as id of the broker that hosts it.

Kafka consumer:
---------------
Consumer can subscribe one or more topics and read messages in the order they were produced
Consumer keeps track of the messages offset which has alreday been read
Consumer work as part of consumer group i:e one or more consumer that work together to consume a topic
Messages with same key will arrive at the same consumer
Each partition is consumed by one consumer
One consumer can read more than one partition 


1. **Producers**  
   - **Function**: Producers are clients that publish (or send) messages to Kafka topics.  
   - **Working**: 
     - **Message Creation**: Producers generate data and send it to Kafka. The message could be 
	 anything from logs, metrics, or transactional data.
     - **Partitioning**: A producer decides which partition within a topic to send the message to.
	 This can be done by specifying a key that determines the partition (using a partitioning algorithm), 
	 or Kafka may distribute messages in a round-robin fashion if no key is provided.
     - **Acknowledgments**: Producers can be configured to wait for acknowledgments from Kafka to ensure 
	 message reliability. For example, with `acks=all`, the producer will wait until the message is replicated 
	 across all in-sync replicas.
     - **Idempotence**: Kafka producers can be configured to be idempotent, ensuring that duplicate messages 
	 are not produced even during retries.

2. **Topics**
   - **Function**: Topics are logical channels to which producers send data and from which consumers read data.
   Kafka topics are like message streams where data is written to and read from.
   - **Working**:
     - **Partitioning**: Topics are divided into multiple partitions. Each partition is a sequence of messages 
	 ordered and immutable. Partitioning provides scalability by allowing Kafka to distribute partitions across 
	 multiple brokers, enabling parallel reads and writes.
     - **Replication**: Each partition in a topic can be replicated across multiple Kafka brokers to provide 
	 redundancy and fault tolerance. This replication factor is defined at the topic level (e.g.,
	 replication factor = 3 means the partition is stored on three brokers).
     - **Data Retention**: Kafka allows configuring retention policies at the topic level. Messages can be 
	 retained based on time (e.g., keep data for 7 days) or size (e.g., store up to 10 GB of data).

3. **Partitions**
   - **Function**: Partitions are the basic unit of scalability and parallelism in Kafka. A partition is an ordered, 
   immutable sequence of records that is continually appended to.
   - **Working**:
     - **Data Distribution**: Partitions allow Kafka to distribute data across multiple brokers, ensuring that 
	 load is distributed and the system can scale horizontally. Multiple consumers can read from different 
	 partitions concurrently.
     - **Data Ordering**: Each partition maintains an order of messages, and Kafka guarantees the order of 
	 messages within a partition.
     - **Offsets**: Each message in a partition is assigned a unique offset, which acts as an identifier and 
	 helps consumers track their position within a partition.

4. **Consumers**
   - **Function**: Consumers are clients that subscribe to Kafka topics and read messages from them.  
   - **Working**:
     - **Offset Management**: Consumers keep track of which messages they have consumed by storing their 
	 current offset (either automatically or manually). Offsets are stored in Kafka itself (or in an external 
	 system if required).
     - **Consumer Groups**: Kafka consumers usually belong to a consumer group. Each consumer in the group reads 
	 data from specific partitions, ensuring that each message is read by one consumer within a group 
	 (for parallelism). If a consumer fails, Kafka reassigns the partitions to other consumers in the group.
     - **Load Balancing**: Kafka balances partition assignment among consumers within the same group. 
	 If the number of consumers is less than the partitions, some consumers may handle more than one partition. 
	 If more consumers are added, partitions are reassigned.

5. **Brokers**
   - **Function**: Kafka brokers are servers that store and manage messages in partitions. 
   They are responsible for message storage, replication, and serving client requests (producing and consuming data).  
   - **Working**:
     - **Leader and Follower Partitions**: For each partition, Kafka selects a broker as the leader, 
	 while others act as followers. Producers and consumers interact with the leader broker, while 
	 followers replicate the data from the leader to maintain consistency.
     - **Replication**: Each broker replicates partitions from other brokers to ensure high availability. 
	 If the leader broker fails, one of the followers is promoted to be the new leader.
     - **Serving Clients**: Brokers handle client requests (both producers and consumers) by serving read 
	 and write operations for the partitions they manage.

6. **Zookeeper/Controller**  
   - **Function**: Zookeeper is a centralized service used by Kafka to manage configuration information, 
   naming, and synchronization across the distributed system. It is also responsible for electing the 
   controller node, which manages leader election and partition assignments.
   - **Working**:
     - **Leader Election**: Zookeeper helps Kafka in electing the controller broker (since Kafka itself is distributed). 
	 The controller is responsible for assigning partitions to brokers and selecting the leader for each partition.
     - **Metadata Management**: Kafka brokers store metadata (such as partition assignments, topic configurations, 
	 and consumer offsets) in Zookeeper.
     - **Failure Detection**: Zookeeper helps detect broker failures and triggers leader re-election for partitions 
	 that had their leader on the failed broker.

   > **Note**: Starting from Kafka 2.8, Kafka introduced the option to run without Zookeeper by using KRaft 
   (Kafka Raft metadata mode), which eliminates Zookeeper and integrates controller functionalities directly into Kafka.

Example: End-to-End Data Flow in Kafka Distributed System**
1. **Message Production**: A producer writes a message to a topic named `user_activity`, 
which has 6 partitions. The producer specifies a key (e.g., user ID) that determines which 
partition the message is sent to.
   
2. **Partition Assignment**: Kafka assigns the message to Partition 4, and the broker responsible
 for Partition 4 stores the message. Other brokers replicate this partition based on the configured replication factor.

3. **Consumer Group**: A group of consumers is subscribed to the `user_activity` topic. Each consumer 
in the group is assigned a subset of partitions to consume messages from. For instance, Consumer A might
 be assigned Partitions 1, 2, and 3, while Consumer B handles Partitions 4, 5, and 6.

4. **Broker Coordination**: The controller node (via Zookeeper or KRaft) ensures that if any broker or 
consumer fails, the partitions are reassigned or a new leader is elected for affected partitions, 
ensuring seamless continuity.
